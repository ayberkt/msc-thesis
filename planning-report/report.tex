\documentclass{article}

\usepackage[utf8]{inputenc}

%% \usepackage{natbib}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage{parskip}
\setlength{\parskip}{10pt} 

\usepackage{tikz}
\usetikzlibrary{arrows, decorations.markings}

\usepackage{chngcntr}
\counterwithout{figure}{section}

\usepackage{multirow}

\begin{document}
\begin{titlepage}

\centering
  
{\scshape\LARGE Master thesis project planning report\\}
  
\vspace{0.5cm}
  
{\huge\bfseries Point-free Topology in Univalent Type Theory\\}
  
\vspace{2cm}

{\Large Ayberk Tosun (\texttt{ayberk@student.chalmers.se})\\}
  
\vspace{1.0cm}
  
{\large Suggested Supervisor at CSE: Thierry Coquand\\}
  
\vspace{1.5cm}
  
{\large Relevant completed courses:\\}
  
{\itshape (Exempted from) Logic in Computer Science\\}
{\itshape (Exempted from) Programming Language Technology\\}
{\itshape Types for Proofs and Programs\\}
{\itshape Models of Computation\\}
{\itshape Formal Methods in Software Engineering\\}
{\itshape Research-oriented Course in Domain Theory\\}
  
\vfill

\vfill
  
{\large \today\\} 

\end{titlepage}

\section{Introduction}

Construction of a semantic model for the untyped $\lambda$-calculus had eluded computer
scientists for quite some time when the first solution was given by Dana Scott in
1969~\cite{scott:1969}; he termed the mathematical structures he used to present a
denotational semantics for the $\lambda$-calculus \emph{domains}, hence giving rise to what is
now known as \emph{domain theory}.

The key insight in Scott's solution was the formulation of an \emph{information ordering}
between terms of the $\lambda$-calculus that orders terms with respect to ``how defined'' they
are. It turns out that considering functions that respect this information ordering in
various ways is crucial for the construction of a semantic model for the untyped
$\lambda$-calculus, and in fact for any programming language that is capable of general
recursion. The information ordering arose from an insight into the topological nature (in
a sense that will be explained later) of the notion of partial information that pervades
the realm of computer science.

Scott initially formulated the theory of domains in the language of lattice
theory~\cite{birkhoff:1940}. Even though this approach enables a smooth development of the
required constructions (for purposes of semantics), it doesn't express the underlying
ideas in their full generality and involves the development of some technical machinery
that seems \emph{ad hoc} when taken out of context. To put it in Scott's
words~\cite[pg.~577]{scott:1982}:

\begin{quote}
  I feel I made a mistake in 1969 in using Lattice Theory as a mode of
  presentation---a mistake as far as Computer Science is concerned.
\end{quote}

It is for this reason that Scott tried another presentation in 1982~\cite{scott:1981}
formulating the notion of \emph{neighbourhood systems}, making a direct link with the
underlying topological insights. Even though this approach turned out to simplify the
presentation, Scott thought they left ``too much implicit'' and hence attempted yet
another formulation of domains, which he called \emph{information systems}.

Right around the time Scott first devised the theory of domains, a mathematical
development was also taking place: the theory of \emph{abstract} or \emph{point-free}
topological spaces in which one takes the notion of a ``set of open sets'' as a primordial
entity and carries out the development based on the algebraic essence of these abstract
opens. Although the pioneering development in this field was done by
Stone~\cite{stone:1934}, it was not until the 1970s that the study of abstract topological
spaces became a discipline of study in its own right with an important paper by John
Isbell~\cite{isbell:1973}.

\emph{Locale theory} emerged as a refinement of the pointless approach to topology~\cite{
johnstone:1982} and it was pointed out that it has direct connections to computer
science in the vein of research instigated by Scott and it turns out that the notion of
information systems was already leaning towards this topological view of computation.

Practically, we may say that locale theory gives us a way to algebraicize the notion of an
\emph{observable property of a program}: a property whose satisfaction an observer can
judge \emph{on the basis of finite information}. This idea builds upon the realization
that observable properties of programs behave like open sets in a topological space.

Abramsky~\cite{abramsky:1991} took advantage of locale theory for the elucidation and
further transformation of domain theory; as he explains \cite{abramsky:1991}, there are
two interpretations of Stone duality:
\begin{enumerate}
  \item the topological view: \emph{points vs. open sets}, and
  \item the logical view: \emph{models vs. formulas}.
\end{enumerate}
the third one that was put forth by Abramsky is:
\begin{center}
  the computer science view: computations vs. their specifications.
\end{center}

To put it more precisely: the fundamental relation of interest in software verification is

\begin{center}
  $P \vDash \phi$, \qquad read as, \qquad ``program $P$ satisfies property $\phi$''.
\end{center}

Stone duality allows us to understand this relationship better: the spatial (``pointful'')
side of the duality enables us to view types as topological spaces consisting of points
and programs as those points whereas the localic (``pointless'') side of the duality
provides a ``logical interpretation of denotational semantics'', as a proof-theoretic
system.

\section{Problem}

In order to state the goal of the thesis project precisely, we provide a more technical
explanation of the problem in this section. Let us start with the question:
\emph{what is topology?}.

Topology is the study of abstract spaces. As classically conceived, a space comprises a
set of locations in the space i.e., its \emph{points}. These are required to satisfy some
axioms characterising what points must behave like. One take on this characterisation that
forms the basis of real analysis is to require a distance function on the space giving the
distance between any two points as a real number and then require this distance function
to behave in a certain way; for example, a set in which the distance between point $x$ and
point $y$ is not the same as that between point $y$ and point $x$ is a surely weird space
that does not meet our intuition of what a space is.

The reason topology is said to study \emph{abstract} spaces is that its approach to
characterising spaces does not involve any reference to ``how near'' two points are. So
topology studies spaces whose inherent notions of nearness are given by finite
\emph{observations} of the space rather than a complete scan of the space revealing all
the information about every point. A fisherman who is not in possession of a sonar to tell
him the distance between every fish in some lake can still have a notion of nearness by
observing what kinds of fish are caught in consecutive casts of his rod.

Let us now formalise this intuition: let $X$ be a set of points. If we had some distance
function $d : X \times X \rightarrow \mathbb{R}$, we could take some $x \in X$ and talk about the set $\{
y\ \|\ d(x, y) < \epsilon \}$ of all points within some distance $\epsilon$ of $x$; this set
approximates $x$ in some sense. Instead of requiring the distance function then, we
require that the set $X$ is equipped with a collection of \emph{open subsets} of $X$ that
are used for approximating points of $X$. Clearly, $X$ itself must be an approximation of
every point it contains so it must be an open set. Similarly, $\emptyset$ contains no points so it
is vacuously an approximation of all the points it contains. If we have two approximation
sets $X_1, X_2$ they both must be approximations of everything they contain so their
intersection is clearly an approximation of what falls in both; a similar observation can
made for unions of approximation sets. Summarizing this up, brings us to the following
definition.

A \emph{topology} on $X$ is a family $\Omega(X)$ of subsets of $X$, called its
\emph{open subsets}, that satisfy:
\begin{itemize}
  \item $X \in \Omega(X)$
  \item for every $O_1, O_2 \subseteq X$ if $O_1, O_2 \in \Omega(X)$ then $O_1 \cap O_2 \in \Omega(X)$.
  \item for every family $\mathcal{F}$ of subsets of $X$, if $\mathcal{F} \subseteq \Omega(X)$ then
    $(\bigcup \mathcal{F}) \in \Omega(X)$.
\end{itemize}

At this point already, one may notice the impredicativity involved in axiom (3) which is
not a good sign from the point-of-view of type theory. We will get back to this later.

Explicit formulation of points within a space was not the manner in which the ancient
Greeks invented geometry. Instead they took a ruler and a compass as being primordial
entities and formulated shapes in terms of them. By this approach, lines are not sets of
points, lines are \emph{pointless} primitive entities.

Topology was invented in a pointful manner in the first place although there is plenty of
motivation for doing it without points. The first and the most relevant justification for
this thesis is the fact non-constructive proofs of point-set topology can be done
constructively in the pointless setting. Although this is quite compelling for anyone who
wishes to write down his proofs as computer programs, the more transcendent reason is that
topology is really a theory of approximations (i.e., observations, experiments) and it
makes a lot of sense to work in a setting where observations are primitive entities much
like taking lines as primitive entities in geometry is a sensible approach.

To move towards a formalism for a ``pointless topological space'', we start by noticing
that the inclusion relation on the collection $\Omega(X)$ of open subsets is crucial so we
characterise it as an order. We take some set $O$ of opens and an ordering relation $\sqsubseteq \subseteq O
\times O$ which must be a partial order that admits finite meets and arbitrary joins.
Furthermore, the following law is also validated in the pointful setting: given some $U \in
\Omega(X)$, $\mathcal{V} \subseteq \Omega(X)$
\begin{equation*}
  X \cap (\bigcup_{i} V_i) = \bigcup_{i} X \cap V_i
\end{equation*}
meaning we must also require that binary meets distribute over arbitrary joins.

Such a partially ordered set that admits all finite meets, all joins, and in which binary
meets distribute over joins is called a \emph{frame}. Frames form a category in which the
morphisms are frame homomorphisms. A \emph{locale}, on the other hand, is an object in the
opposite category of the category of frames. So locales are identical to frames as long as
no reference to morphisms are made. Locales play a more important role that frames do
hence giving the theory its name.

A powerful technique in locale theory is that of a \emph{presentation} originating from
the realm of universal algebra. We start with an algebraic theory $F$ providing a
syntactic specification for an algebra. The presentation of an $F$-algebra $A$ is then a
pair of a set of \emph{generators} and a set of \emph{relations} such that $A$ is the
freest algebra that is generated by the generators satisfying the relations.

The presentation method is crucial for at least two reasons: first, it gives a way of
expressing locales in a predicative manner therefore rendering them amenable to
development in type theory; secondly, as Sambin puts it~\cite{sambin:2007}, it allows us
to express frames using finitely many rules that look a lot like inference rules. This
allows the importation of proof-theoretic methods and ideas into topology, providing a
tangible handle on various topologies.

So how are locales related to logic and computation? The idea is that we can view locales
as \emph{systems of verifiable properties} i.e. properties whose validity can be judged on
the basis of a finite amount of information. Execution of a computer program is a possibly
infinite structure in that it might never terminate. However, we can still look at finite
prefixes of the output it produces and judge that it meets certain properties. This is
analogous to the aforementioned example of drawing open balls arounds points in that even
though we cannot pinpoint the complete behaviour of the program we approximate it by its
observable/verifiable properties. This seemingly superficial insight runs surprisingly
deep.

Examination of the behaviour of verifiable properties shows that verifiable properties
satisfy the locale laws.

\section{Goals and Challenges}

As mentioned before, it is an interesting problem to do locale theory in predicative type
theory. The effort to do this has given rise to \emph{formal topology} which focuses on
one particular way of presenting frames called the coverage method.

The goal of this thesis will be to carry out a development of pointless topology in
univalent type theory (i.e., in which \emph{equivalent} types can be identified), focusing
specifically on the presentation method. The idea is that a univalent setting provides a
suitable setting for the development for the development of locale theory which will
involve, for example, homotopy levels.

There are a few possible challenges...

%% TODO: comment on the challenges.

\section{Possible applications}

One immediate application of this development will be to define domains in terms of
locales and formalise a computationally adequate semantic model for PCF, that is, a model
in which the semantic equality of two programs entails their operational equality. (The
intuition is that if a model is computationally adequate, it is as useful as an
interpreter.) Formalisation of such a model would be interesting in itself as there are
many other formalisations of semantic models in type theory and it would be interesting to
see how the locale-theoretic approach affects the same development.

Another possible application springs from the fact that in domain theory computable
functions are interpreted as continuous functions between domains, or in our case, between
certain kind of locales. Once a model for PCF has been developed, for instance, to show
that a certain function is not PCF-computable it suffices to show that the corresponding
semantic function is not continuous. This gives a much more different way of thinking and
reasoning about computability.

Once we develop a locale-theoretic model for PCF, it would be an interesting application
to prove the undecidability of certain well-known problems (e.g., the Post correspondence
problem, diophantine equations, aperiodic tilings) through the use of topological methods
and see if it simplifies the standard proof or at least experiment with the topological
manifestation of the proof.

\section{Approach}

The technical development will be carried out in the type-theoretic proof assistant
Agda~\cite{norell:2008}. Until recently, Agda did not have intrinsic support for the
univalence axiom which was remedied with the development of Cubical
Agda~\cite{cubicalagda}. Cubical Agda is an implementation of Cubical Type Theory (CTT)
developed specifically to serve as a setting in which the computational meaning of the
univalence axiom can be understood. Development of the mathematical results in a
type-theoretic proof assistant such as Agda will not only ensure the validity of
mathematical constructions and arguments but also reveal the computational nature of the
proofs involved.

The thesis report will then be an informalisation of the formal development.

For some of the applications we have proposed, it might be interesting to actually run the
roofs as standalone programs (e.g., real number computation, the Tychonoff theorem) that
do IO. As Agda provides the user with fine-grained control over how the compiled programs
look like, we believe it will provide an ideal setting for such applications.

\section{Time plan}

A tentative plan for the thesis work is provided in Table \ref{table:plan}.

\begin{table}[]\caption{Work plan.}\label{table:plan}
\begin{tabular}{lll}
&      Week no. & Milestone                                                                  \\\hline
\multirow{3}{*}{Sep} & W37  & Submission deadline for planning report. \\
                     & W38  & Complete formalisation of basic ideas from universal algebra. \\
                     & W39  & Complete formalisation of presentation for a space. \\ \hline
\multirow{4}{*}{Oct} & W40  & Formalise the adjunction between spatialisation and localification. \\
                     & W41  & Continue work from W40. Formalise sober spaces. \\
                     & W42  & \\
                     & W43  & \\ \hline
\multirow{4}{*}{Nov} & W44  & \\
                     & W45  & \\
                     & W46  & \\
                     & W47  & \\ \hline
\multirow{4}{*}{Dec} & W48  & \\
                     & W49  & \\
                     & W50  & \\
                     & W51  & \\ \hline
\multirow{4}{*}{Jan} & W01  & \\
                     & W02  & \\
                     & W03  & \\
                     & W04  & \\ \hline
\multirow{4}{*}{Feb} & W05  & \\
                     & W06  & \\
                     & W07  & \\
                     & W08  & \\ \hline
\multirow{4}{*}{Mar} & W09  & \\
                     & W10  & \\
                     & W11  & \\
                     & W12  & \\ \hline
\multirow{4}{*}{Apr} & W13  & Finalise first draft of the report. \\
                     & W14  & \\
                     & W15  & \\
                     & W16  & \\ \hline
\multirow{4}{*}{May} & W17  & \\
                     & W18  & \\
                     & W19  & \\
                     & W20  & \\
\end{tabular}
\end{table}

\newpage
\bibliographystyle{plain}
\bibliography{references}

\end{document}
