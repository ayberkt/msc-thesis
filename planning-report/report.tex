\documentclass{article}

\usepackage[utf8]{inputenc}

%% \usepackage{natbib}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage{parskip}
\setlength{\parskip}{10pt} 

\usepackage{tikz}
\usetikzlibrary{arrows, decorations.markings}

\usepackage{chngcntr}
\counterwithout{figure}{section}

\begin{document}
\begin{titlepage}

\centering
  
{\scshape\LARGE Master thesis project planning report\\}
  
\vspace{0.5cm}
  
{\huge\bfseries Point-free Topology in Univalent Type Theory\\}
  
\vspace{2cm}
  
{\Large Ayberk Tosun (\texttt{ayberk@student.chalmers.se})\\}
  
\vspace{1.0cm}
  
{\large Suggested Supervisor at CSE: Thierry Coquand\\}
  
\vspace{1.5cm}
  
{\large Relevant completed courses:\\}
  
{\itshape (Exempted from) Logic in Computer Science\\}
{\itshape (Exempted from) Programming Language Technology\\}
{\itshape Types for Proofs and Programs\\}
{\itshape Models of Computation\\}
{\itshape Formal Methods in Software Engineering\\}
{\itshape Research-oriented Course in Domain Theory\\}
  
\vfill

\vfill
  
{\large \today\\} 

\end{titlepage}

\section{Introduction}

Construction of a semantic model for the untyped $\lambda$-calculus had eluded computer
scientists for quite some time when the first solution was given by Dana Scott in
1969~\cite{scott:1969}; he termed the mathematical structures he used to present a
denotational semantics for the $\lambda$-calculus \emph{domains}, hence giving rise to what is
now known as \emph{domain theory}.

The key insight in Scott's solution was the formulation of an \emph{information ordering}
between terms of the $\lambda$-calculus that orders terms with respect to ``how defined'' they
are. It turns out that considering functions that respect this information ordering in
various ways is crucial for the construction of a semantic model for the untyped
$\lambda$-calculus, and in fact for any programming language that is capable of general
recursion. The information ordering arose from an insight into the \emph{topological nature}
(in a sense that will be explained later) of the notion of partial information that
pervades the realm of computer science.

Scott initially formulated the theory of domains in the language of lattice
theory~\cite{birkhoff:1940}. Even though this approach enables a smooth development of the
required constructions (for purposes of semantics), it doesn't express the underlying
ideas in their full generality and involves the development of some technical machinery
that seems \emph{ad hoc} when taken out of context. To put it in Scott's
words~\cite[pg.~577]{scott:1982}:

\begin{quote}
  I feel I made a mistake in 1969 in using Lattice Theory as a mode of
  presentation---a mistake as far as Computer Science is concerned.
\end{quote}

It is for this reason that Scott tried another presentation in 1982~\cite{scott:1981}
formulating the notion of \emph{neighbourhood systems}, making a direct link with the
underlying topological insights. Even though this approach turned out to simplify the
presentation, Scott thought they left ``too much implicit'' and hence attempted yet
another formulation of domains, which he called \emph{information systems}.

Right around the time Scott first devised the theory of domains, a mathematical
development was also taking place: the theory of \emph{abstract} or \emph{point-free}
topological spaces in which one takes the notion of a ``set of open sets'' as a primordial
entity and carries out the development based on the algebraic essence of these abstract
opens. Although the pioneering development in this field was done by
Stone~\cite{stone:1934}, it was not until the 1970s that the study of abstract topological
spaces became a discipline of study in its own right with an important paper by John
Isbell~\cite{isbell:1973}.

\emph{Locale theory} emerged as a refinement of the pointless approach to topology~\cite{
johnstone:1982} and it was pointed out that it has direct connections to computer
science in the vein of research instigated by Scott and it turns out that the notion of
information systems was already leaning towards this topological view of computation.

Practically, we may say that locale theory gives us a way to algebraicize the notion of an
\emph{observable property of a program}: a property whose satisfaction an observer can
judge \emph{on the basis of finite information}. This idea builds upon the realization
that observable properties of programs behave like open sets in a topological space.

Abramsky~\cite{abramsky:1991} took advantage of locale theory for the elucidation and
further transformation of domain theory; as he explains \cite{abramsky:1991}, there are
two interpretations of Stone duality:
\begin{enumerate}
  \item the topological view: \emph{points vs. open sets}, and
  \item the logical view: \emph{models vs. formulas}.
\end{enumerate}
the third one that was put forth by Abramsky is:
\begin{center}
  the computer science view: computations vs. their specifications.
\end{center}

To put it more precisely: the fundamental relation of interest in software verification is

\begin{center}
  $P \vDash \phi$, \qquad read as, \qquad ``program $P$ satisfies property $\phi$''.
\end{center}

Stone duality allows us to understand this relationship better: the spatial (``pointful'')
side of the duality enables us to view types as topological spaces consisting of points
and programs as those points whereas the localic (``pointless'') side of the duality
provides a ``logical interpretation of denotational semantics'', as a proof-theoretic
system.

\section{Goals and Challenges}

%% TODO.

\section{Approach}

As previously mentioned, I will be using Cubical Agda~\cite{cubicalagda} which as an
extension of the Agda proof assistant~\cite{norell:2008}. Let us start by briefly
explaining what Cubical Type Theory is (or rather what it achieves).

The development of Homotopy Type Theory (HoTT)~\cite{hottbook} has been a substantial
advancement throughout the history of type theory if not all of mathematical foundations.
From the practical point of view, HoTT provides the user with access to the following
technical advantages that revolve around the \emph{univalence axiom}. For the sake of
brevity, we refrain from engaging in a technical explanation of the univalence axiom and
instead focus on the more practical applications:

\begin{itemize}
  \item \emph{Function extensionality}. It is extremely common for Agda users to postulate
    function extensionality which is not a theorem of type theory. However, it was proven
    by Voevodsky that function extensionality is a theorem in a univalent setting.
  \item \emph{Homotopy levels}. TODO: explain.
  \item \emph{Higher inductive types}. Normally inductive types are defined by defining
    what inhabitants they have. The notion of a higher inductive type extends this idea by
    allowing the user to add \emph{equalities} (i.e., new inhabitants of the identity
    type) in the type therefore identifying some of the elements.
\end{itemize}

A severe shortcoming of HoTT has been the fact that univalence needs to postulated. In
light of the view of type theory as a practical programming language, this means that
\emph{we do not know how to run programs that make use of univalence}.

The computational meaning of univalence was came to light with by the development of
\emph{cubical type theory}~\cite{cubicaltt} in which the univalence axiom is a theorem.
This is an amazing result in a sense in that it allows a programmer to prove insertion
sort (extensionally) equal to quicksort and then a develop a theory of their programs that
use quicksort as though they used insertion sort.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
