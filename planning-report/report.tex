\documentclass{article}

\usepackage[utf8]{inputenc}

%% \usepackage{natbib}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{graphicx}

\usepackage{parskip}
\setlength{\parskip}{10pt} 

\usepackage{tikz}
\usetikzlibrary{arrows, decorations.markings}

\usepackage{chngcntr}
\counterwithout{figure}{section}

\begin{document}
\begin{titlepage}

\centering
  
{\scshape\LARGE Master thesis project planning report\\}
  
\vspace{0.5cm}
  
{\huge\bfseries Point-free Topology in Univalent Type Theory\\}
  
\vspace{2cm}

{\Large Ayberk Tosun (\texttt{ayberk@student.chalmers.se})\\}
  
\vspace{1.0cm}
  
{\large Suggested Supervisor at CSE: Thierry Coquand\\}
  
\vspace{1.5cm}
  
{\large Relevant completed courses:\\}
  
{\itshape (Exempted from) Logic in Computer Science\\}
{\itshape (Exempted from) Programming Language Technology\\}
{\itshape Types for Proofs and Programs\\}
{\itshape Models of Computation\\}
{\itshape Formal Methods in Software Engineering\\}
{\itshape Research-oriented Course in Domain Theory\\}
  
\vfill

\vfill
  
{\large \today\\} 

\end{titlepage}

\section{Introduction}

Construction of a semantic model for the untyped $\lambda$-calculus had eluded computer
scientists for quite some time when the first solution was given by Dana Scott in
1969~\cite{scott:1969}; he termed the mathematical structures he used to present a
denotational semantics for the $\lambda$-calculus \emph{domains}, hence giving rise to what is
now known as \emph{domain theory}.

The key insight in Scott's solution was the formulation of an \emph{information ordering}
between terms of the $\lambda$-calculus that orders terms with respect to ``how defined'' they
are. It turns out that considering functions that respect this information ordering in
various ways is crucial for the construction of a semantic model for the untyped
$\lambda$-calculus, and in fact for any programming language that is capable of general
recursion. The information ordering arose from an insight into the \emph{topological nature}
(in a sense that will be explained later) of the notion of partial information that
pervades the realm of computer science.

Scott initially formulated the theory of domains in the language of lattice
theory~\cite{birkhoff:1940}. Even though this approach enables a smooth development of the
required constructions (for purposes of semantics), it doesn't express the underlying
ideas in their full generality and involves the development of some technical machinery
that seems \emph{ad hoc} when taken out of context. To put it in Scott's
words~\cite[pg.~577]{scott:1982}:

\begin{quote}
  I feel I made a mistake in 1969 in using Lattice Theory as a mode of
  presentation---a mistake as far as Computer Science is concerned.
\end{quote}

It is for this reason that Scott tried another presentation in 1982~\cite{scott:1981}
formulating the notion of \emph{neighbourhood systems}, making a direct link with the
underlying topological insights. Even though this approach turned out to simplify the
presentation, Scott thought they left ``too much implicit'' and hence attempted yet
another formulation of domains, which he called \emph{information systems}.

Right around the time Scott first devised the theory of domains, a mathematical
development was also taking place: the theory of \emph{abstract} or \emph{point-free}
topological spaces in which one takes the notion of a ``set of open sets'' as a primordial
entity and carries out the development based on the algebraic essence of these abstract
opens. Although the pioneering development in this field was done by
Stone~\cite{stone:1934}, it was not until the 1970s that the study of abstract topological
spaces became a discipline of study in its own right with an important paper by John
Isbell~\cite{isbell:1973}.

\emph{Locale theory} emerged as a refinement of the pointless approach to topology~\cite{
johnstone:1982} and it was pointed out that it has direct connections to computer
science in the vein of research instigated by Scott and it turns out that the notion of
information systems was already leaning towards this topological view of computation.

Practically, we may say that locale theory gives us a way to algebraicize the notion of an
\emph{observable property of a program}: a property whose satisfaction an observer can
judge \emph{on the basis of finite information}. This idea builds upon the realization
that observable properties of programs behave like open sets in a topological space.

Abramsky~\cite{abramsky:1991} took advantage of locale theory for the elucidation and
further transformation of domain theory; as he explains \cite{abramsky:1991}, there are
two interpretations of Stone duality:
\begin{enumerate}
  \item the topological view: \emph{points vs. open sets}, and
  \item the logical view: \emph{models vs. formulas}.
\end{enumerate}
the third one that was put forth by Abramsky is:
\begin{center}
  the computer science view: computations vs. their specifications.
\end{center}

To put it more precisely: the fundamental relation of interest in software verification is

\begin{center}
  $P \vDash \phi$, \qquad read as, \qquad ``program $P$ satisfies property $\phi$''.
\end{center}

Stone duality allows us to understand this relationship better: the spatial (``pointful'')
side of the duality enables us to view types as topological spaces consisting of points
and programs as those points whereas the localic (``pointless'') side of the duality
provides a ``logical interpretation of denotational semantics'', as a proof-theoretic
system.

\section{Problem}

In order to state the goal of the thesis project precisely, we provide a more technical
explanation of the problem in this section. Let us start with the question:
\emph{what is topology?}.

Topology is the study of abstract spaces. As classically conceived, a space comprises a a
set of locations in the space i.e., its \emph{points}. These are required to satisfy some
axioms characterising what points must behave like. One take on this characterisation that
forms the basis of real analysis is to require a distance function on the space giving the
distance between any two points as a real number, and then require this distance function
to behave in a certain way; for example, a set in which the distance between point $x$ and
point $y$ is not the same as that between point $y$ and point $x$ is a surely weird space
that does not meet our intuition of what a space is.

The reason topology is said to study \emph{abstract} spaces is that its approach to
characterising spaces does not involve any reference to ``how near'' two points are. So
topology studies spaces whose inherent notions of nearness is given by finite
\emph{observations} of the space rather than a complete scan of the space revealing all
the information about every point. A fisherman who is not in possession of a sonar to tell
him the distance between every fish in some lake can still have a notion of nearness by
observing what kinds of fish are caught in consecutive casts of his rod.

Let us now formalise this intuition: let $X$ be a set of points. If we had some distance
function $d : X \times X \rightarrow \mathbb{R}$, we could take some $x \in X$ and talk about the set
$\{ y\ \|\ d(x, y) < \epsilon \}$ of all points within some distance $\epsilon$ of $x$; this set
approximates $x$ in some sense. Instead of requiring the distance function then, we
require that the set $X$ is equipped with a collection of \emph{open} subsets of $X$ that
are used for approximating points of $X$. $X$ is itself must be an approximation of every
point it contains so it must be an open set. Similarly, $\emptyset$ contains no points so it is
vacuously an approximation of all the points it contains. If we have two approximation
sets $X_1, X_2$ are both approximations of everything they contain so their intersection
is clearly an approximation of what falls in both; a similar observation can made for
unions of approximation sets. Summarizing this up, brings us to the following definition.

A \emph{topology} on $X$ is a collection of subsets of $\Omega(X) \subseteq P(X)$, called its
\emph{open subsets}, that satisfy:
\begin{itemize}
  \item $X \in \Omega(X)$
  \item $O_1, O_2 \in \Omega(X)$, $O_1 \cap O_2 \in \Omega(X)$
  \item $O \subseteq \Omega(X)$, $\bigcup O \in \Omega(X)$.
\end{itemize}

A set $X$ equipped with a topology is called a \emph{topological space}.

Explicit formulation of points within a space was not the manner in which the ancient
Greeks invented geometry. Instead they took a ruler and a compass as being primordial
entities and formulated shapes in terms of them. By this approach, lines are not sets of
points, lines are \emph{pointless} primitive entities.

Topology was invented in a pointful manner in the first place although there is plenty of
motivation for doing it without points. The first and the most relevant for this thesis is
the fact non-constructive proofs of point-set topology can be done constructively in the
pointless setting. Although this is quite compelling for anyone who wishes to write down
his proofs as a computer program, the more transcendent reason is that topology is really
a theory of approximations (i.e., observations, experiments) and it makes a lot of sense
work in a setting where observations are primitive entities much like it makes sense to
take lines as primitive entities for geometry.

Now the question
To move towards a
\emph{pointless} formulation of topology, we start by noticing that the inclusion relation
on the collection $\Omega(X)$ of open subsets is crucial and start by characterising it as an
abstract order. We take some set $O$ of opens and an ordering relation $\sqsubseteq \subseteq O \times O$ which
must be partial order that admits finite meets and arbitrary joins. Furthermore, the
following law is also validated in the pointful setting: given some $U \in \Omega(X)$,
$\mathcal{V} \subseteq \Omega(X)$

\begin{equation*}
  X \cap (\bigcup_{i} V_i) = \bigcup_{i} X \cap V_i
\end{equation*}
meaning we must also require that binary meets distribute over arbitrary joins. Such a
partially ordered set that admits all finite meets, all joins, and in which binary meets
distribute over joins is called a \emph{frame}. Frames form a category in which the
morphisms are frame homomorphisms. A \emph{locale} is an object in the opposite category
of the category of frames. So locales are identical to frames as long as no reference to
morphisms are made. Locales play a more important role that frames do

A powerful technique in pointless topology is that of a \emph{presentation} originating
from the realm of universal algebra. We start with an algebraic theory $F$ providing a
syntactic specification for an algebra. The presentation of an $F$-algebra $A$ is then a
pair of a set of \emph{generators} and a set of \emph{relations} such that $A$ generated
\emph{freely} by these generators and relations.

So how are locales related to logic and computation? The idea is that we can view locales
as \emph{systems of verifiable properties} i.e. properties whose validity can be judged on
the basis of a finite amount of information. Examination of the behaviour of verifiable
properties shows that they satisfy the locale laws.

An example is the familiar set of real numbers: we can never pinpoint the value of a real
number $r$, only judge that it lies within some range $q \pm \epsilon$ where $q, \epsilon \in \mathbb{Q}$
and $\epsilon \ge 0$. When $r$ lies within $q \pm \epsilon$ we write
\begin{equation*}
  r \vDash q \pm \epsilon
\end{equation*}
denoting a \emph{finite observation} on $r \in \mathbb{R}$. We can also take our domain as
the set of programs in some programming language and take the set of opens to be the set
of observable properties, properties whose validity can be judged after observing a finite
prefix of the sequence of outputs the program produces.

The reason that the presentation method is crucial to pointless topology is that the
theory of locales is usually developed in an \emph{impredicative} setting, such as a
topos. Although one can express the notion of a locale predicatively, is not possible, for
instance, to define the product of two locales in a predicative manner.

\section{Goals and Challenges}


The question of how one can develop locale theory in type theory then arises. One answer
is that it is possible to engage in a predicative development for those locales that have
presentations. Although not every locale is presentable, many interesting locales are. One
convenient way of presenting a locale is using the coverage method invented by Johnstone
(???).

The goal of my thesis will be to carry out a development of pointless topology in
univalent type theory which provides a suitable setting for the development of the
technical machinery involved in locale theory.

There are a few possible challenges...

\section{Approach}

The technical development will be carried out in the type-theoretical proof assistant
Agda~\cite{norell:2008}. Until recently, Agda did not have intrinsic support for the
univalence axiom which was remedied with the development of Cubical
Agda~\cite{cubicalagda} which is an implementation of Cubical Type Theory (CTT) developed
specifically to serve as a setting in which the computational meaning of the univalence
axiom can be understood. Development of the mathematical results in a type-theoretic proof
assistant such as Agda will ensure the validity of mathematical constructions and
arguments.

The thesis report will then be an informalisation of the formal development.

For some of the applications we have proposed, it might be interesting to actually run the
proofs as standalone programs (e.g., real number computation, the Tychonoff theorem) that
do IO. As Agda provides the user with fine-grained control over how the compiled programs
look like, we believe it will provide an ideal setting for such applications.

\bibliographystyle{plain}
\bibliography{references}

\end{document}
